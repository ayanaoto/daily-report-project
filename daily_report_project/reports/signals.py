# reports/signals.py
from django.db.models.signals import post_save
from django.dispatch import receiver
from .models import Report, RequiredItem
import re
import unicodedata

# ã€è¿½åŠ ã€‘ã‚¨ãƒ©ãƒ¼è§£æ¶ˆã®ãŸã‚ã«å¿…è¦ãªimport
from datetime import datetime, date
from django.utils import timezone


# ==== ãƒ‡ãƒãƒƒã‚°ãƒ•ãƒ©ã‚° ====
DEBUG_EXTRACT = False  # Trueã«ã™ã‚‹ã¨ã€ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã«æŠ½å‡ºã®è©³ç´°ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™

# ----------------------------------------------------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°: è¤‡æ•°ã®å€™è£œã‹ã‚‰å®‰å…¨ã«ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã‚’å–å¾—
# ----------------------------------------------------------------------
def _get_attr(obj, names: list[str], default: str = ""):
    """
    ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‹ã‚‰å±æ€§å€¤ã‚’å–å¾—ã—ã¾ã™ã€‚
    namesãƒªã‚¹ãƒˆã« ['work_content', 'content'] ã®ã‚ˆã†ã«è¤‡æ•°ã®å€™è£œã‚’æŒ‡å®šã§ãã¾ã™ã€‚
    """
    for name in names:
        if hasattr(obj, name):
            value = getattr(obj, name)
            if value is not None:
                return value
    return default

# ----------------------------------------------------------------------
# ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å¿…è¦ãªç‰©å“ã‚’æŠ½å‡ºã™ã‚‹é–¢æ•°
# ----------------------------------------------------------------------
def extract_needed_items_final(text: str) -> list[str]:
    if not text or not text.strip():
        return []

    text_norm = unicodedata.normalize("NFKC", text)
    SEP_CLASS = r"ã¨ã‚„ã€"
    SEP = rf"[{SEP_CLASS}]"
    PARTICLES = "ãŒã‚’ã¯ã‚‚ã«ã¸ã§ã®"
    PARTICLE_CLASS = f"[{PARTICLES}]"
    ITEM_TOKEN = r"[^\sã€‚ã€ï¼ï¼Œï¼ï¼Ÿâ€¦{}{}]+".format(SEP_CLASS, PARTICLES)
    ITEM_GROUP = rf"{ITEM_TOKEN}(?:{SEP}{ITEM_TOKEN})*"
    OPTIONAL_PARTICLE = r"(?:[ãŒã‚’ã¯ã‚‚ã«ã¸ã§ã¨ã‚„ã€ã®]?)*"
    TRIGGER_CORE = r"(?:å¿…è¦|ç”¨æ„|æº–å‚™|è³¼å…¥|æ‰‹é…|ã„ã‚‹|è¦ã‚‹)"
    AFTER_TRIGGER_TAIL = r"(?:ã™ã‚‹|ã—ãŸ|ã—ã¦|ã—ã¾ã™|ã—|äºˆå®š|ã§ã—ãŸ|ã§ã™|ã |ã§|ã¾ã™|ã—ã¦ãŠã|ã™ã‚‹äºˆå®š)?"
    
    pat_pair_needed = re.compile(rf"(?P<a>{ITEM_TOKEN})ã¨(?P<b>{ITEM_TOKEN})[ãŒã¯]{OPTIONAL_PARTICLE}(?:å¿…è¦){AFTER_TRIGGER_TAIL}")
    pat_direct = re.compile(rf"(?P<items>{ITEM_GROUP}){OPTIONAL_PARTICLE}(?P<trg>{TRIGGER_CORE}){AFTER_TRIGGER_TAIL}")
    pat_sahen = re.compile(rf"(?P<items>{ITEM_GROUP}){OPTIONAL_PARTICLE}(?P<trg>è³¼å…¥|ç”¨æ„|æº–å‚™){OPTIONAL_PARTICLE}(?:ã™ã‚‹|ã—ãŸ|ã—ã¦|ã—ã¾ã™|ã™ã‚‹äºˆå®š)")
    pat_bridge = re.compile(rf"(?P<items>{ITEM_GROUP}){OPTIONAL_PARTICLE}(?:[^\sã€‚ï¼ï¼Ÿâ€¦]{{1,10}}){{0,3}}(?P<trg>{TRIGGER_CORE}){AFTER_TRIGGER_TAIL}")

    STOPWORDS = {"ä»Šæ—¥", "ãã‚‡ã†", "ä»Šæ—¥ã¯", "ãã‚‡ã†ã¯", "æ˜æ—¥", "ã‚ã—ãŸ", "æ˜å¾Œæ—¥", "ã‚ã•ã£ã¦", "ã‚ã¨", "ãã‚Œã‹ã‚‰", "ã•ã‚‰ã«", "è¿½åŠ ã§", "äºˆå®š", "ä»¥ä¸Š", "ç­‰", "ãªã©"}
    TRIGGER_ALL = re.compile(r"(å¿…è¦|ç”¨æ„|æº–å‚™|è³¼å…¥|æ‰‹é…|ã„ã‚‹|è¦ã‚‹)")
    LEADING_CONNECTIVE = re.compile(r"^(?:ä»Šæ—¥ã¯|ãã‚‡ã†ã¯|ä»Šæ—¥|ãã‚‡ã†|ã‚ã¨|ãã‚Œã‹ã‚‰|ã•ã‚‰ã«)")
    STRIP_PUNCT_HEAD = re.compile(r"^[ã€ã€‚ï¼ï¼Œâ€¦ï¼ï¼Ÿ!?\-â€”ãƒ»:ï¼š;ï¼›ï¼ˆï¼‰\(\)\[\]ã€Œã€ã€ã€\"'`]+")
    STRIP_PUNCT_TAIL = re.compile(r"[ã€ã€‚ï¼ï¼Œâ€¦ï¼ï¼Ÿ!?\-â€”ãƒ»:ï¼š;ï¼›ï¼ˆï¼‰\(\)\[\]ã€Œã€ã€ã€\"'`]+$")

    def _choose_by_particles(s: str) -> str:
        parts = re.split(PARTICLE_CLASS, s)
        if len(parts) <= 1: return s
        left, right = parts[0], parts[-1]
        left_clean, right_clean = TRIGGER_ALL.sub("", left), TRIGGER_ALL.sub("", right)
        candidates = [c for c in [left_clean.strip(), right_clean.strip()] if c]
        if not candidates: return s
        if len(candidates) == 2: return candidates[0] if len(candidates[0]) >= len(candidates[1]) else candidates[1]
        return candidates[0]

    def _clean_item(raw: str) -> str | None:
        s = raw.strip()
        if not s: return None
        s = STRIP_PUNCT_HEAD.sub("", s)
        s = STRIP_PUNCT_TAIL.sub("", s)
        s = LEADING_CONNECTIVE.sub("", s)
        s = TRIGGER_ALL.sub("", s)
        if re.search(PARTICLE_CLASS, s): s = _choose_by_particles(s)
        s = STRIP_PUNCT_HEAD.sub("", s)
        s = STRIP_PUNCT_TAIL.sub("", s)
        s = re.sub(rf"^{PARTICLE_CLASS}+", "", s)
        s = re.sub(rf"{PARTICLE_CLASS}+$", "", s)
        is_kanji_1char = bool(re.fullmatch(r"[\u4E00-\u9FFF]", s))
        if not s or s in STOPWORDS or (len(s) == 1 and not is_kanji_1char): return None
        return s

    found_spans, items = set(), set()
    for m in pat_pair_needed.finditer(text_norm):
        span = m.span()
        if span in found_spans: continue
        found_spans.add(span)
        a, b = _clean_item(m.group("a")), _clean_item(m.group("b"))
        if a: items.add(a)
        if b: items.add(b)

    for pat in [pat_direct, pat_sahen, pat_bridge]:
        for m in pat.finditer(text_norm):
            span = m.span()
            if span in found_spans: continue
            found_spans.add(span)
            for raw in re.split(SEP, m.group("items")):
                cleaned = _clean_item(raw)
                if cleaned: items.add(cleaned)
    return list(items)

# ----------------------------------------------------------------------
# Reportãƒ¢ãƒ‡ãƒ«ä¿å­˜å¾Œã®ã‚·ã‚°ãƒŠãƒ«ãƒãƒ³ãƒ‰ãƒ©
# ----------------------------------------------------------------------
@receiver(post_save, sender=Report)
def report_post_save_handler(sender, instance: Report, created: bool, **kwargs):
    print(f"âœ… Reportä¿å­˜å¾Œ: ã‚·ã‚°ãƒŠãƒ«ç™ºç« ID: {instance.id}")

    work_content = _get_attr(instance, ["work_content", "content", "ä½œæ¥­å†…å®¹"], "")
    note = _get_attr(instance, ["note", "remarks", "å‚™è€ƒ"], "")
    text_to_analyze = f"{work_content}\n{note}".strip()

    if not text_to_analyze:
        print("âš ï¸ å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®ãŸã‚ã€ToDoä½œæˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã—ãŸã€‚")
        return

    print(f"ğŸ“ è§£æå¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆ:\n---\n{text_to_analyze}\n---")
    
    found_items = extract_needed_items_final(text_to_analyze)
    print(f"ğŸ” æŠ½å‡ºã•ã‚ŒãŸã‚¢ã‚¤ãƒ†ãƒ : {found_items}")

    date_field = _get_attr(instance, ["date", "report_date", "created_at"])
    report_date = date_field if isinstance(date_field, (datetime, date)) else timezone.now()
    todo_title = f"{report_date.strftime('%Y/%m/%d')}ã®æ—¥å ±ã‹ã‚‰è‡ªå‹•ä½œæˆ"
    
    existing_todo, deleted = RequiredItem.objects.filter(
        assignee=instance.author,
        title=todo_title,
    ).delete()
    if deleted:
        print(f"ğŸ—‘ï¸ æ—¢å­˜ã®ã¾ã¨ã‚ToDoã‚’å‰Šé™¤ã—ã¾ã—ãŸ: {deleted}")

    if not found_items:
        print("â„¹ï¸ æŠ½å‡ºã‚¢ã‚¤ãƒ†ãƒ ãŒãªã„ãŸã‚ã€ToDoã¯ä½œæˆã—ã¾ã›ã‚“ã€‚")
        return

    todo_body = "\n".join(f"ãƒ»{item}" for item in found_items)

    try:
        RequiredItem.objects.create(
            title=todo_title,
            assignee=instance.author,
            required_items_list=todo_body,
            is_done=False,
        )
        print(f"âœ… ToDoä½œæˆæˆåŠŸ: '{todo_title}'")
    except Exception as e:
        print(f"âŒ ToDoä½œæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")